# -*- coding: utf-8 -*-
"""KneeMRI-Keras_Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lld3wd9vou3G18G22CVLflCBwCU_Lftm

<h2>A.I. based X-Ray analysis for human lungs. Implemented by Keras and Tensorflow</h2>
<p>Prepared by Vytautas Bielinskas, vytautas.bielinskas@gmail.com</p>
<h3>Part 1: Construct the CNN Architecture and train the model with real data</h3>
"""

from google.colab import files
src = list(files.upload().values())[0]
open('vb100_utils.py','wb').write(src)
import vb100_utils

# Commented out IPython magic to ensure Python compatibility.
# Import modules and packages
import numpy as np
import pandas as pd
import itertools
import os, stat, time
from os.path import dirname as up

import tensorflow as tf
import keras
from keras import backend as K
from keras.models import Sequential
from keras.layers import Activation
from keras.layers.core import Dense, Flatten, Dropout
from keras.optimizers import Adam
from keras.optimizers import RMSprop
from keras.metrics import categorical_crossentropy
from keras.regularizers import l2
from keras.preprocessing.image import ImageDataGenerator
from keras.layers.convolutional import *
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD

from matplotlib import pyplot as plt

from sklearn.metrics import confusion_matrix
from vb100_utils import *

#from vb100_utils import *
from shutil import copyfile
import shutil
import glob
from PIL import Image

import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline
from google.colab import drive

!pip install sklearn
!pip install -U matplotlib
!pip install Pillow

drive.mount('/content/drive')

data_dir = '/content/drive/MyDrive/Data/'
!ls -lh $data_dir

print('Tensorflow version = {}'.format(tf.__version__))
print('Keras version = {}'.format(keras.__version__))

"""<b># Data Pre-processing automatically</b>"""

# Data Folder System: -------------------------------------------------
# data
# -- test (234 + 390 = 624)
# ---- NORMAL
# ------ IM-0001-0001.jpeg
# ------ IM-0003-0001.jpeg
# ------ (234 images)
# ---- PNEUMONIA
# ------ person1_virus_6.jpeg
# ------ person109_bacteria_526.jpeg
# ------ (390 images)
# -- train (1341 + 3875 = 5216)
# ---- NORMAL
# ------ IM-0115-0001.jpeg
# ------ IM-0117-0001.jpeg
# ------ (1341 images)
# ---- PNEUMONIA
# ------ person1_bacteria_1.jpeg
# ------ person162_virus_322.jpeg
# ------ (3875 images)
# -- val (8 + 8 = 16)
# ---- NORMAL
# ------ NORMAL2-IM-1427-0001.jpeg
# ------ NORMAL2-IM-1440-0001.jpeg
# ------ (8 images)
# ---- PNEUMONIA
# ------ person1946_bacteria_4874.jpeg
# ------ person1951_bacteria_4882.jpeg
# ------ (8 images)

# In total: 234 + 390 + 3875 + 8 + 8 = 4515 imges (1.2GB of data)
# -----------------------------------------------------------------------

"""<img src="imgs/01.jpeg" alt="Folder system" width="550">"""

# CONSTANTS FOR DIRECTORIES
TRAIN_DIR = '/content/drive/MyDrive/Data/train'
VALID_DIR = '/content/drive/MyDrive/Data/valid'
#TEST_DIR = '/content/drive/MyDrive/Data/test'
#TEST_DIR = '/content/drive/MyDrive/Data/train'
l_DIRS = [TRAIN_DIR, VALID_DIR]
POSITIVE_CLASS = 'ABNORMAL'
ABSTRACT_CLASS = 'ACL'

# CONSTANTS FOR IMAGE PARAMETERS
INPUT_W = 1200 # pixels
INPUT_H = 900  # pixels
DIVIDER = 3.6
INPUT_DIM = (int(INPUT_W/DIVIDER), int(INPUT_H/DIVIDER), 1)
BATCH_SIZE_TRAIN = 64
BATCH_SIZE_TEST = 64 
BATCH_SIZE_VALID = 16
NORMALIZER = 1./255
IMAGE_FORMAT = '.npy'

# Output Info
print('Image dimmensions for CNN = {}'.format(INPUT_DIM))

if abstract_class_exists(ABSTRACT_CLASS, l_DIRS):
   structure_origin_data(l_DIRS, IMAGE_FORMAT, POSITIVE_CLASS)

classes = classes_for_each_set(l_DIRS)

print('Catched classes for the model:\n{}'.format(classes))

from glob import glob
planes = ['axial', 'coronal', 'sagittal']
datasets = {'train': TRAIN_DIR, 'valid': VALID_DIR}

for dataset, path in datasets.items():
    print(f'\nNumber of exams in {dataset} set:')
    for plane in planes:
      print(plane, len(glob(f'{path}/{plane}/*.npy')))

# Generating and Plot Image Data from Train Set
TRAIN_BATCHES = ImageDataGenerator(rescale=NORMALIZER).\
    flow_from_directory(TRAIN_DIR,
    color_mode='grayscale',
    target_size=INPUT_DIM[0:2],
    classes=classes['TRAIN'],
    class_mode="categorical",
    shuffle=True,
    batch_size=BATCH_SIZE_TRAIN)

imgs, labels = next(TRAIN_BATCHES)  # <-- Extracting image matrixes and labels
plots(imgs, titles=labels)          # <-- Plot Images with labels
#train_imgs = rgb_to_grayscale(imgs) # <-- Convert RGB images to Grayscale ones by Tensorflow
#train_labels = labels

# Generating and Plot Image Data from Test Set
TEST_BATCHES = ImageDataGenerator(rescale=NORMALIZER).\
    flow_from_directory(VALID_DIR,
    color_mode='grayscale',
    target_size=INPUT_DIM[0:2],
    classes=classes['VALIDATION'],
    class_mode="categorical",
    shuffle=True,
    batch_size=BATCH_SIZE_TEST)

imgs, labels = next(TEST_BATCHES)   # <-- Extracting image matrixes and labels
plots(imgs, titles=labels)          # <-- Plot Images with labels

# Generating and Plot Image Data from Validation Set
VAL_BATCHES = ImageDataGenerator(rescale=NORMALIZER).\
    flow_from_directory(VALID_DIR,
    color_mode='grayscale',
    target_size=INPUT_DIM[0:2],
    classes=classes['VALIDATION'],
    class_mode="categorical",
    shuffle=True,
    batch_size=BATCH_SIZE_VALID)

imgs, labels = next(VAL_BATCHES)   # <-- Extracting image matrixes and labels
plots(imgs, titles=labels)         # <-- Plot Images with labels
#val_imgs = rgb_to_grayscale(imgs)  # < -- Convert RGB images to Grayscale ones by Tensorflow
#val_labels = labels

print(f'First 5 items in {TRAIN_DIR}/axial/\n')
!ls $train_dir/axial | head -5

# Output of Generators
for data_batch, label_batch in TRAIN_BATCHES:
    print('data batch shape = {}'.format(data_batch.shape))
    print('labels batch shape = {}'.format(label_batch.shape))
    break

"""<b># Build CNN with Keras</b>"""

# Build the CNN model
model = Sequential()
model.add(Conv2D(64, (5, 5), input_shape=(INPUT_DIM)))
model.add(Activation('relu'))
model.add(MaxPooling2D((3, 3)))

model.add(Conv2D(128, (4, 4))) 
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(512, (3, 3))) 
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(512, (3, 3))) 
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(512, (3, 3))) 
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(512, (2, 2))) 
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten()) 

model.add(Dense(512, kernel_regularizer=regularizers.l2(0.02))) 
model.add(Activation('relu'))

model.add(Dense(3)) 
model.add(Activation('softmax'))

model.summary()

# Define an optimizer for the model
opt = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
#opt = SGD(lr=0.01, decay=1e-6, momentum=0.85, nesterov=True)
#opt = RMSprop(lr=0.001, rho=0.8, epsilon=None, decay=0.0)

model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)

print('steps_per_epoch={}'.format(int(5215 / BATCH_SIZE_TRAIN)))
print('validation_steps={}'.format(int(624 / BATCH_SIZE_TEST)))

"""<b># Train the CNN with Training data</b>"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model.fit_generator(
#     TRAIN_DIR,
#     steps_per_epoch=len(TRAIN),
#     validation_data=TEST_BATCHES,
#     validation_steps=len(TEST_BATCHES),
#     epochs=100,
#     verbose=2
# )
# 
# # Parameters meanings:
# # steps_per_epoch = number_of_images / batch_size = 5215 / 64 = 82:
# # --- Total number of steps (batches of samples) to yield from generator before declaring one 
# #     epoch finished and starting the next epoch. It should typically be equal to the number 
# #     of unique samples of your dataset divided by the batch size.
# # Verbose:
# # -- 0 (quiet): you just get the total numbers of tests executed and the global result
# # -- 1 (default): you get the same plus a dot for every successful test or a F for every failure
# # -- 2 (verbose): you get the help string of every test and the result

plot_model_result(model)

"""<p><i>More saved models are stored on the project directory as <code>good_models</code>. There are subsystem contain graphs, weights and CNN architectures for each training experiment.</i></p>"""

# Save the results as separate lists
df = save_model_result(model)

"""<h3>Part 2. Make it resuable</h3>"""

# Save the Model Weights
model.save_weights('model_100_eopchs_adam_20191030_01.h5')

# Save the Model to JSON
model_json = model.to_json()
with open('model_adam_20191030_01.json', 'w') as json_file:
    json_file.write(model_json)
    
print('Model saved to the disk.')

# Useful references:
# -- https://www.youtube.com/watch?v=daovGOlMbT4
# -- https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/

# ------------------------------------------------------------------------
# Load saved model and its weights
'''
>> Model weights are saved to HDF5 format.
>> The model structure can be described and saved using two different formats: JSON and YAML.
'''

# Import dependencies
from keras.optimizers import Adam
from tensorflow.keras.models import model_from_json
from tensorflow.python.framework import ops
ops.reset_default_graph()
import h5py 
from PIL import Image
import PIL
from vb100_utils import *

print('h5py version is {}'.format(h5py.__version__))

# Get the architecture of CNN
json_file = open('./good_models/20190807/02/model_adam.json')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)

# Get weights into the model
loaded_model.load_weights('./good_models/20190807/02/model_100_eopchs_adam_20190807.h5')

'''
Here I will simulate what will happen during deployment on a cloud.
Reading a given image, preparing it for CNN evaluation and make
a predictions with a returned class from a dictionary that has
been used for training.
'''

# Define optimizer and run
opt = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)
loaded_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop')


'''
Important Note! For this block optimizer is entered manualy as Tensorflow object.
For future, need to change it for include it as variable with full set of
parameters as Tensorflow variable.

'''

IMG = Image.open('data/val/BACTERIA/person1950_bacteria_4881.jpeg')
print(type(IMG))
IMG = IMG.resize((342, 257))
IMG = np.array(IMG)
print('po array = {}'.format(IMG.shape))
IMG = np.true_divide(IMG, 255)
IMG = IMG.reshape(1, 342, 257, 1)
print(type(IMG), IMG.shape)

predictions = loaded_model.predict(IMG)

print(loaded_model)
predictions_c = loaded_model.predict_classes(IMG)
print(predictions, predictions_c)

classes = {'TRAIN': ['BACTERIA', 'NORMAL', 'VIRUS'],
           'VALIDATION': ['BACTERIA', 'NORMAL'],
           'TEST': ['BACTERIA', 'NORMAL', 'VIRUS']}

predicted_class = classes['TRAIN'][predictions_c[0]]
print('We think that is {}.'.format(predicted_class.lower()))

"""<h2>That is all for Jupyter.</h2>
<p>Go to deployment stage now.</p>
"""